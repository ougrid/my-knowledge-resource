{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ougrid/my-knowledge-resource/blob/master/pose_estimation_sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workshop: Pose Estimation"
      ],
      "metadata": {
        "id": "v5Ol7TW1k9Fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download image and video data from https://drive.google.com/drive/folders/14kmXX_ZCEOtt8lChmHEdCuZTqiNbL9W4?usp=drive_link"
      ],
      "metadata": {
        "id": "DohcdnyKv9du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "-DsbSdoOlEwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHmPAg1O53Pm"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "s4Oi989p6EnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained YOLOv8n-pose Pose model\n",
        "model = YOLO('yolov8n-pose.pt')\n",
        "\n",
        "# Run inference on an image\n",
        "results = model('bus.jpeg')\n",
        "\n",
        "# or run inference with batch processing\n",
        "#results = model(['bus.jpeg', 'test.png'])"
      ],
      "metadata": {
        "id": "ZYb_DS5r6ePw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the keypoints\n",
        "print(results[0].keypoints)"
      ],
      "metadata": {
        "id": "V4jwTzOEBCr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the results\n",
        "for r in results:\n",
        "\n",
        "    # Plot results image\n",
        "    image_draw = r.plot(boxes=False)\n",
        "\n",
        "    # Display results\n",
        "    cv2_imshow(np.array(image_draw))"
      ],
      "metadata": {
        "id": "6ZO68z2ZGZyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Process pose estimation in video"
      ],
      "metadata": {
        "id": "GV5c09p0xLbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the video file\n",
        "video_path = 'sample.avi'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, 25, (frame_width, frame_height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    if success:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = model(frame)\n",
        "        # Plot results image\n",
        "        image_draw = results[0].plot(boxes=False)\n",
        "\n",
        "        # write frame to video\n",
        "        out.write(np.array(image_draw))\n",
        "\n",
        "    else:\n",
        "        # End the loop if no more frames are available\n",
        "        break\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "45q279fW3fqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVyT5mfV9Ma5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}